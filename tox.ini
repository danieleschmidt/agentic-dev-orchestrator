# Tox configuration for multi-environment testing
# https://tox.readthedocs.io/

[tox]
envlist = 
    py38,
    py39,
    py310,
    py311,
    py312,
    coverage,
    lint,
    security,
    docs,
    integration,
    performance
isolated_build = true
skip_missing_interpreters = true

# Default test environment
[testenv]
deps = 
    pytest>=7.0
    pytest-cov>=4.0
    pytest-mock>=3.10
    pytest-xdist>=3.0
    pytest-asyncio>=0.21
    pytest-benchmark>=4.0
    coverage[toml]>=7.0
    factory-boy>=3.2
    freezegun>=1.2
    PyYAML>=6.0
    requests>=2.28.0
    python-dotenv>=0.19.0
commands = 
    pytest {posargs:tests/unit tests/integration}
setenv =
    PYTHONPATH = {toxinidir}
    TESTING = true
    ADO_LOG_LEVEL = DEBUG
allowlist_externals = 
    rm
    find

# Coverage testing
[testenv:coverage]
deps = 
    {[testenv]deps}
    coverage-badge
commands = 
    coverage run -m pytest tests/unit tests/integration
    coverage report --show-missing
    coverage html
    coverage xml
    coverage json
    # Generate coverage badge
    coverage-badge -o coverage.svg -f

# Code quality and linting
[testenv:lint]
deps = 
    black>=23.0
    ruff>=0.1.0
    mypy>=1.0
    types-PyYAML
    types-requests
    types-python-dateutil
commands = 
    black --check --diff .
    ruff check .
    mypy . --ignore-missing-imports

# Format code
[testenv:format]
deps = 
    black>=23.0
    ruff>=0.1.0
    isort>=5.12
commands = 
    black .
    ruff check --fix .
    isort .

# Security scanning
[testenv:security]
deps = 
    bandit>=1.7
    safety>=2.3
    pip-audit>=2.6
    semgrep
commands = 
    bandit -r . -f json -o bandit-report.json
    safety check --json --output safety-report.json
    pip-audit --output-format=json --output-file=pip-audit-report.json
    semgrep --config=auto --json --output=semgrep-report.json .

# Documentation building
[testenv:docs]
deps = 
    sphinx>=6.0
    sphinx-rtd-theme>=1.2
    myst-parser>=1.0
    mkdocs>=1.4
    mkdocs-material>=9.0
    mkdocstrings[python]>=0.20
commands = 
    # Build Sphinx docs
    sphinx-build -b html docs docs/_build/html
    # Build MkDocs
    mkdocs build

# Integration tests
[testenv:integration]
deps = 
    {[testenv]deps}
commands = 
    pytest {posargs:tests/integration} -v --tb=short
setenv =
    {[testenv]setenv}
    INTEGRATION_TESTING = true

# End-to-end tests
[testenv:e2e]
deps = 
    {[testenv]deps}
    docker
    docker-compose
commands = 
    pytest {posargs:tests/e2e} -v --tb=short -s
setenv =
    {[testenv]setenv}
    E2E_TESTING = true

# Performance tests
[testenv:performance]
deps = 
    {[testenv]deps}
    pytest-benchmark
    memory-profiler
    py-spy
commands = 
    pytest {posargs:tests/performance} -v --benchmark-only --benchmark-sort=mean
setenv =
    {[testenv]setenv}
    PERFORMANCE_TESTING = true

# Python 3.8 specific
[testenv:py38]
deps = {[testenv]deps}
commands = {[testenv]commands}

# Python 3.9 specific
[testenv:py39]
deps = {[testenv]deps}
commands = {[testenv]commands}

# Python 3.10 specific
[testenv:py310]
deps = {[testenv]deps}
commands = {[testenv]commands}

# Python 3.11 specific
[testenv:py311]
deps = {[testenv]deps}
commands = {[testenv]commands}

# Python 3.12 specific
[testenv:py312]
deps = {[testenv]deps}
commands = {[testenv]commands}

# Build and test package
[testenv:build]
deps = 
    build
    twine
    wheel
commands = 
    python -m build
    twine check dist/*

# Clean artifacts
[testenv:clean]
deps = 
commands = 
    rm -rf build/
    rm -rf dist/
    rm -rf *.egg-info/
    rm -rf .tox/
    rm -rf .pytest_cache/
    rm -rf .coverage
    rm -rf htmlcov/
    rm -rf .mypy_cache/
    rm -rf .ruff_cache/
    find . -type d -name __pycache__ -exec rm -rf {{}} +
    find . -type f -name "*.pyc" -delete

# Dependency updates
[testenv:deps]
deps = 
    pip-tools
    pip-audit
commands = 
    pip-compile requirements.in
    pip-audit

# Pre-commit
[testenv:pre-commit]
deps = 
    pre-commit
commands = 
    pre-commit run --all-files

# All checks (comprehensive)
[testenv:all]
deps = 
    {[testenv:lint]deps}
    {[testenv:security]deps}
    {[testenv]deps}
commands = 
    {[testenv:lint]commands}
    {[testenv:security]commands}
    {[testenv:coverage]commands}

# Development environment
[testenv:dev]
deps = 
    {[testenv]deps}
    {[testenv:lint]deps}
    {[testenv:docs]deps}
    jupyterlab
    ipykernel
    notebook
commands = 
    pip list
    python --version
    pytest --version

# Parallel testing
[testenv:parallel]
deps = 
    {[testenv]deps}
commands = 
    pytest -n auto {posargs:tests/unit tests/integration}

# Stress testing
[testenv:stress]
deps = 
    {[testenv]deps}
    locust
commands = 
    pytest tests/performance -v -k "stress"

# Memory profiling
[testenv:memory]
deps = 
    {[testenv]deps}
    memory-profiler
    pympler
commands = 
    python -m memory_profiler tests/performance/profile_memory.py

# Type checking only
[testenv:typecheck]
deps = 
    mypy>=1.0
    types-PyYAML
    types-requests
    types-python-dateutil
commands = 
    mypy . --strict --ignore-missing-imports

# Minimal test (fast feedback)
[testenv:minimal]
deps = 
    pytest
commands = 
    pytest tests/unit -x -q --tb=short

# Test specific markers
[testenv:unit]
deps = {[testenv]deps}
commands = pytest -m "unit" {posargs}

[testenv:integration_only]
deps = {[testenv]deps}
commands = pytest -m "integration" {posargs}

[testenv:slow]
deps = {[testenv]deps}
commands = pytest -m "slow" {posargs}

[testenv:fast]
deps = {[testenv]deps}
commands = pytest -m "not slow" {posargs}

# GitHub Actions specific
[testenv:github]
deps = {[testenv]deps}
commands = 
    pytest --cov=. --cov-report=xml --cov-report=term-missing {posargs}

# Test data generation
[testenv:testdata]
deps = 
    {[testenv]deps}
    faker
commands = 
    python scripts/generate_test_data.py